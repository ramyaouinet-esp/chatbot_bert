{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Bag1ZF1tRiIP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "class QA:\n",
        "    \"\"\"\n",
        "    HuggingFace BERT language model pre-trained on SQUAD.\n",
        "    Ref: https://huggingface.co/transformers/index.html\n",
        "\n",
        "    How does BERT answer questions?\n",
        "    Ref: https://openreview.net/pdf?id=SygMXE2vAE\n",
        "    \"\"\"\n",
        "    def __init__(self, text_file):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "\n",
        "        with open(text_file, 'r') as file:\n",
        "            self.passage = file.read().replace('\\n', ' ')\n",
        "\n",
        "    def ask(self, question, threshold=1.0):\n",
        "        \"\"\"Ask question to QA.\"\"\"\n",
        "        score, answer = self.query(question)\n",
        "        print(\"NLP score:\", score)\n",
        "        print(\"Answer:\", answer)\n",
        "\n",
        "        if score > threshold:\n",
        "            return answer\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def query(self, question):\n",
        "      \"\"\"\n",
        "      Query question with reference to the previously given passage.\n",
        "      Returns (score, answer)\n",
        "      \"\"\"\n",
        "      # Truncate the input passage to fit within the maximum sequence length\n",
        "      max_passage_length = self.tokenizer.model_max_length\n",
        "      truncated_passage = self.passage[:max_passage_length - len(question) - 10]  # Subtracting for \"[CLS] \", \"[SEP] \", and some buffer\n",
        "      input_text = \"[CLS] \" + question + \" [SEP] \" + truncated_passage + \" [SEP]\"\n",
        "\n",
        "      input_ids = self.tokenizer.encode(input_text)\n",
        "      token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))]\n",
        "      outputs = self.model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n",
        "\n",
        "      start_logits = outputs.start_logits\n",
        "      end_logits = outputs.end_logits\n",
        "\n",
        "      # Convert start_logits and end_logits to tensors if they are not already\n",
        "      if not isinstance(start_logits, torch.Tensor):\n",
        "          start_logits = torch.tensor(start_logits)\n",
        "      if not isinstance(end_logits, torch.Tensor):\n",
        "          end_logits = torch.tensor(end_logits)\n",
        "\n",
        "      all_tokens = self.tokenizer.convert_ids_to_tokens(input_ids)\n",
        "      start_index = torch.argmax(start_logits)\n",
        "      end_index = torch.argmax(end_logits) + 1\n",
        "      score = self.compute_score(start_logits, end_logits)\n",
        "      answer = ' '.join(all_tokens[start_index: end_index])\n",
        "\n",
        "      return score, answer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def compute_score(self, start_scores, end_scores):\n",
        "        \"\"\"\n",
        "        Compute the final score based on start and end scores.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            start_scores = torch.nn.functional.softmax(start_scores, dim=1)\n",
        "            end_scores = torch.nn.functional.softmax(end_scores, dim=1)\n",
        "            score = torch.max(start_scores) + torch.max(end_scores)\n",
        "            return round(score.item(), 3)\n",
        "        except Exception as e:\n",
        "            print(\"Error computing score:\", e)\n",
        "            return 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = QA(\"/content/QACorpus.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqT6dIHpR24Z",
        "outputId": "c2406a46-479e-4a25-a826-85166ea3cd50"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score, answer = qa.query(\"How many USP admits Each year ?\")\n",
        "print(\"Answer:\", answer)\n",
        "print(\"Score:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUuDIx8aRrRA",
        "outputId": "540b047e-4130-4386-ed3c-feeb35aae621"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: around 200\n",
            "Score: 1.486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score, answer = qa.query(\"How much discount is given for school fees?\")\n",
        "print(\"Answer:\", answer)\n",
        "print(\"Score:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW6XM6TxRvkH",
        "outputId": "33b1e73c-5aeb-4964-81fd-c1d4ab18a888"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 200\n",
            "Score: 0.331\n"
          ]
        }
      ]
    }
  ]
}